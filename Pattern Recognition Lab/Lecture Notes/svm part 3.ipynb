{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us apply KKT conditions on the SVM primal problem and get the dual problem:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KKT condition 1 : You have to differentiate wrt both $w$ and $b$:\n",
    "- Differentiating wrt $w$ yields: \n",
    "\n",
    "\\begin{equation}\n",
    "              w = \\sum_{i=1}^{n} \\lambda_i y_i x_i\n",
    "           \\end{equation}\n",
    "           \n",
    "  Differentiating wrt $b$:\n",
    "     \\begin{equation}\n",
    "               \\sum_{i=1}^{n} \\lambda_i y_i = 0\n",
    "           \\end{equation}\n",
    "- KKT condition 2:\n",
    "       \n",
    "\\begin{equation} \\lambda_i \\geq 0 \\end{equation}\n",
    "\n",
    "- KKT condition 3 : \n",
    "\\begin{equation} y_i(w^Tx_i + b) - 1 \\geq 0 \\end{equation}\n",
    "\n",
    "- KKt condition 4:\n",
    "\\begin{equation}\n",
    "    \\lambda_i( y_i(w^Tx_i + b)-1) = 0\n",
    "\\end{equation}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the condition 4. The lagrangian multiplier can be non-zero only if $y_i(w^Tx_i + b)==1$. This means that lagrangian multiplier corresponding to nearest points to the hyperplane can only be non-zero. And by condition $1$ only they take part in deciding the hyperplane. That is points further away from the plane do not have any role to play in defining the hyperplane. These points are called ***Support Vectors***.\n",
    "\n",
    "Now plugging the expression from condition $1$ into the Lagrangean along with the constraints on the Lagrangean multipliers lead to the following dual formulation:\n",
    "\n",
    "   \\begin{equation}\n",
    "    \\max  \\sum_i \\sum_j \\lambda_i \\lambda_j x_i^Tx_j - \\sum_i \\lambda_i\n",
    "   \\end{equation}\n",
    " subject to \n",
    "   \\begin{equation} 0 \\leq \\lambda_i   \\forall i \\in \\{1,2...n\\}\\end{equation}\n",
    "   \\begin{equation} \\sum_{i=1}^{n} \\lambda_i y_i = 0 \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We usually go for the minimization problem:\n",
    "    \\begin{equation}\n",
    "    \\min  -\\sum_i \\sum_j \\lambda_i \\lambda_j x_i^Tx_j + \\sum_i \\lambda_i\n",
    "   \\end{equation}\n",
    " subject to \n",
    "   \\begin{equation}0 \\leq \\lambda_i   \\forall i \\in \\{1,2...n\\}\\end{equation}\n",
    "   \\begin{equation} \\sum_{i=1}^{n} \\lambda_i y_i = 0 \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearly non-separable case :\n",
    "\n",
    "Till now we assumed the given set of points are linearly separable. That is, there exists a solution that satisfies each of the constraints. But there can be scenario where the data points are not separable. That is, there will atleast be one $x_i$ for which $y_i(w^Tx_i + b) \\geq 1$ is not true. \n",
    "\n",
    "In such cases, we relax the constraints by adding slack variables $\\epsilon_i$ and change the constraint to $y_i(w^Tx_i + b) \\geq 1-\\epsilon_i$ . But then we have to restrict $\\epsilon_i$ because setting it to large value can make the constraint redundant (beacuse it will always be true).\n",
    "\n",
    "Therefore we add that to the objective function. The modified primal problem is :\n",
    "    \\begin{equation}\n",
    "         \\min_{w,b} \\lVert w \\rVert + C \\sum_i \\epsilon_i\n",
    "        \\end{equation}\n",
    "        \n",
    "subject to \n",
    "        \\begin{equation}\n",
    "          y_i(w^Tx_i + b) \\geq 1-\\epsilon_i \\; \\forall i = 1 ...n \n",
    "        \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Framing of the solution based on the KKT conditions is left to reader. The dual problem is directly stated here without \n",
    "the derivation:\n",
    "\n",
    "   \\begin{equation}\n",
    "    \\min  -\\sum_i \\sum_j \\lambda_i \\lambda_j x_i^Tx_j + \\sum_i \\lambda_i\n",
    "   \\end{equation}\n",
    " subject to \n",
    "   \\begin{equation} 0 \\leq \\lambda_i \\leq C \\;\\; \\forall i \\in \\{1,2...n\\}\\end{equation}\n",
    "   \\begin{equation} \\sum_{i=1}^{n} \\lambda_i y_i = 0 \\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Minimal Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
