{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- So far we estimated the density by assuming a functional form and then estimating the parameters of the function\n",
    "- Some times the distribution may not fit any of the typical distributions that are assumed.\n",
    "- In this case we may have to find a way to estimate the distribution without making such assumptions and which depends on the data set available to us only.\n",
    "- Since there is no functional form assumed there is no parameter to be estimated. Hence the method discussed today is generally called **Non-parametric Estimation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we do make certain assumptions about the probability density function estimated. Denoted by $f(x)$ it is assumed to be suitably smooth (differentiable). And we have the a collection of observations (data samples) which come from the distribution $f(x)$. We denote the data set by $X = \\{ x_1,x_2,x_3 \\cdots x_N\\} $. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we do is to break the input space into bins and measure the frequency of each bin ( number of data points in each bin). Let us see how this works by considering the one dimensional case. Divide the x-axis into bins of length h and count how many data points fall in each bin. For instance suppose $k_i$ elements fall in the $i^{th}$ bin out of a total of $N$ elements. Then our notion of probability prompts us to say that the probability of the bin is $P_i = \\frac{k_i}{N}$. Let the bin cover an interval of length say $h$. If $h$ is small enough then we can assume that the pdf is constant over the bin. This implies that $P_i = \\hat p(x) h $ or $\\hat p(x) = \\frac{P_i}{h} = \\frac{k_i}{Nh}$ where $x$ is any point on the bin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question under what conditions will this converge to the true pdf $p(x)$. What is the ideal interval length $h$? Clearly large $h$ will result in a relatively smooth function $\\hat p(x)$ and too small an interval results in spiky estimate. Moreover if a large interval is chosen then the assumption that the pdf is constant over the region does not hold. On the other hand too small an interval can result in bins with no points at all resulting in discontinuities in the estimated pdf. Therefore it is imperative that a concrete analysis of the properties of this estimation is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notations : \n",
    "1. Define $ 1(u) =  \\begin{cases} 1 \\; if \\; \\lvert u \\rvert < 1/2 \\\\ 0 \\; otherwise \\end{cases}$. Therefore $1(\\frac{x-x_i}{h}) = 1$ only if $x_i \\in (x-h/2,x+h/2)$. Also note that the integral of the function $1$ is 1.\n",
    "We shall express the estimated pdf $\\hat p(x) $ interms of $1$ as : \n",
    "\\begin{equation} \\hat p(x) = \\frac{1}{nh} \\sum_{i=1}^{n} 1(\\frac{x-x_i}{h}) \\end{equation}\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is what is the optimal interval width $h$ for a given sample size $n$. On what ground can we define optimality? Clearly from the discussion above we agree that $h$ has to be small. But then how small for a given sample size. One intuitive heuristic is that for a small sample size $n$ if too small an interval is chosen then it can happen that none of the $x_i$'s fall in the interval. This would lead to the estimate $\\hat p(x) $ to become $0$. Therefore you cannot afford to have a very small interval. On the other hand if the number of samples is very high then it is possible to have a small interval and the estimate is likely to be close to the actual pdf $p(x)$. The key to controlling the accuracy of the estimate is to control the parameter $h$ as a function of the sample size. Let us see what is the relation. For that we need certain quantities to be computed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important quantities \n",
    "1. $E(1(\\frac{x-x_i}{h})) = \\int_{x_i} 1(\\frac{x-x_i}{h}) p(x_i) dx_i $ <br\\> By using change of variables by defining $u = \\frac{x-x_i}{h} $ we can rewrite the integral as : $ \\int_{x_i} 1(u) p(x - uh) dx_i $ <br\\>\n",
    " Apply Taylor series expansion of $p(x-uh)$ as $p(x) - uhp'(x) + O(h^2)$. Putting this into the definition of expectation we get : <br\\>\n",
    " $E(1(\\frac{x-x_i}{h})) = \\int_{u} 1(u) (p(x) - uhp'(x) + O(h^2)) h du = hp(x) + o(h^2) $. <br\\>\n",
    " We can use this to find the expectation of the estimate $\\hat p(x)$ which is given below:<br\\>\n",
    " $E{\\hat p(x) } = \\frac{1}{nh} \\sum_{i}^{n} E{1(\\frac{x-x_i}{h})} = p(x) + O(h^2) $  <br\\>  \n",
    "2. $ Var{1(\\frac{x-x_i}{h})} = E 1^2(\\frac{x-x_i}{h}) - (E1(\\frac{x-x_i}{h}))^2 = hp(x) + O(h^2)$. Using this we can compute the variance of $\\hat p(x) $ as : \n",
    "\\begin{equation}\n",
    "Var(\\hat p(x)) = \\sum_i^{n} Var(\\frac{1}{nh}1(\\frac{x-x_i}{h}) = \\frac{1}{nh^2}(hp(x) + O(h^2)) = \\frac{p(x)}{nh} + O(\\frac{1}{n})) \n",
    "\\end{equation}\n",
    "3. $Bias(\\hat p(x)) = (E\\hat p(x) - p(x))^2 = O(h^4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is measured in terms of the mean squared error $E(\\hat p(x) - p(x))^2 $. In order for the estimate to be consistent ( that is, it converges to the true density $p(x)$) the mse should converge to 0 asymptotically (wrt n).\n",
    "We need to have a strategy to choose $h$ for large $n$ that mse goes to 0. <br\\>\n",
    "Let us have a closer look at mse. It may be noted that $mse = bias(\\hat p(x)) + var(\\hat p(x)) = \\frac{p(x)}{nh} + O(\\frac{1}{n})) + O(h^4)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore for mse to converge to 0 asymptotically $h^4 \\rightarrow 0, \\frac{1}{nh} \\rightarrow 0$ as $n \\rightarrow \\infty$. For both to happen we choose h such that $h^4$ and $\\frac{1}{nh} $ are asymptotically equal. That is \n",
    "$h^4 = \\Theta(\\frac{1}{nh} ) \\implies h = \\Theta( \\frac{1}{n^{1/5}} ) $ . This gives a guidance in the choice of the interval length $h$ for a given sample size $n$. With this choice you can easily see that mse decreases as $O(\\frac{1}{n^{4/5}} )$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parzen Window Estimation\n",
    "Looking at the estimate of p(x) written as a sum of discontinuous square functions $1()$ \n",
    "centered at $x_i$ we can see that the estimate is not smooth. \n",
    "In fact the derivate of $\\hat p(x)$ is either $0$ or does not exist. \n",
    "Therefore this kernel was replaced by smoother functions like Gaussian which satisfy certain conditions. Denoted by $K()$ \n",
    "they:\n",
    "     1. are Symmetric about 0 (even functions)\n",
    "     2. are Non-negative (because we are trying to model a non-negative function)\n",
    "     3. satisfy $\\int K(u)du=1$ (this makes sure that the estimate will also integrate to 1)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the estimate has the form $\\hat p(x) = \\sum_{i=1}^{n} \\frac{1}{nh} K(\\frac{x-x_i}{h})$. Prove that integral of $\\hat p(x)$ is 1. It is non-negative obviously because of non-negativity of $K$. The analysis of this function also proceeds along the same lines as in the case of using the square window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important quantities \n",
    "K. $E(K(\\frac{x-x_i}{h})) = \\int_{x_i} K(\\frac{x-x_i}{h}) p(x_i) dx_i $ <br\\> By using change of variables by defining $u = \\frac{x-x_i}{h} $ we can rewrite the integral as : $ \\int_{x_i} K(u) p(x - uh) dx_i $ <br\\>\n",
    " Apply Taylor series expansion of $p(x-uh)$ as $p(x) - uhp'(x) + O(h^2)$. Putting this into the definition of expectation we get : <br\\>\n",
    " $E(K(\\frac{x-x_i}{h})) = \\int_{u} K(u) (p(x) - uhp'(x) + O(h^2)) h du = hp(x) + o(h^2) $. <br\\>\n",
    " We can use this to find the expectation of the estimate $\\hat p(x)$ which is given below:<br\\>\n",
    " $E{\\hat p(x) } = \\frac{K}{nh} \\sum_{i}^{n} E{K(\\frac{x-x_i}{h})} = p(x) + O(h^2) $  <br\\>  \n",
    "2. $ Var{K(\\frac{x-x_i}{h})} = E K^2(\\frac{x-x_i}{h}) - (EK(\\frac{x-x_i}{h}))^2 = hp(x)\\int K^2(u)du + O(h^2)$. Using this we can compute the variance of $\\hat p(x) $ as : \n",
    "\\begin{equation}\n",
    "Var(\\hat p(x)) = \\sum_i^{n} Var(\\frac{1}{nh}K(\\frac{x-x_i}{h}) = \\frac{1}{nh^2}(hp(x) + O(h^2)) = \\frac{p(x)}{nh} + O(\\frac{1}{n})) \n",
    "\\end{equation}\n",
    "3. $Bias(\\hat p(x)) = (E\\hat p(x) - p(x))^2 = O(h^4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case above the mean squared error is the sum of bias and variance and hence arguing in the same way we reach the relation $h^4 = \\Theta(\\frac{1}{nh})$ between $h$ and $1/nh$. This leads to $h = \\Theta(\\frac{1}{n^{1/5}})$. Practically $h$ is taken as $\\frac{c}{n^{1/5}}$. Determining $c$ is also an estimation problem. In the example code below the constant $c$ was found by trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3d931c9f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def squareKernel(u):\n",
    "    if abs(u)>=0 and abs(u)<=1:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def parzenWindow(x, xtrain, h, kernel = 'g'):\n",
    "    n = xtrain.shape[0]\n",
    "    z = np.subtract(xtrain, x)/h\n",
    "    if kernel == 'g':\n",
    "        pdf = ((1/np.sqrt(2*np.pi))*np.exp(-(z*z)/2)).sum()\n",
    "    if kernel == 's':\n",
    "        g = np.vectorize(squareKernel, otypes=[np.ndarray])\n",
    "        pdf = g(z).sum()\n",
    "    pdf = pdf/(n*h)\n",
    "    return pdf\n",
    "\n",
    "n = 1500\n",
    "xdata = np.linspace(-10,10,1000)\n",
    "xtrain = np.random.randn(n)\n",
    "xtrain = np.concatenate((xtrain,5+0.3*np.random.randn(2*n)))\n",
    "#xtrain = np.concatenate((xtrain,-4+0.7*np.random.randn(n)))\n",
    "ntotal = xtrain.shape[0]\n",
    "c = 25\n",
    "h = c/math.pow(ntotal,0.8)\n",
    "p = []\n",
    "for x in xdata:\n",
    "    p.append(parzenWindow(x,xtrain,h,kernel='g'))\n",
    "\n",
    "plt.plot(xdata,p)\n",
    "plt.hist(xtrain, normed=1)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
