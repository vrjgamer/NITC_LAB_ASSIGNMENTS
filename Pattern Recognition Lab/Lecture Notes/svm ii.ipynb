{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution of the final formulation requires Karush Kuhn Tucker conditions for optimiality. Here we will take a digressin to discuss the fundamentals of convex optimzation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Consider the following constrained optimization problem.(We call it the primal problem) :\n",
    "\\begin{align}\n",
    "     minimize \\; & f(x)\\\\\n",
    "     subject \\; to \\; & g_i(x) \\leq 0 \\; i=1..n \\\\\n",
    "            & h_i(x) = 0 \\; i=1..m\n",
    "\\end{align}\n",
    "\n",
    "There are $n+m$ constraints that need to be satisfied by the solution to the problem. We say an $x$ is feasible if it \n",
    "satisfies all the constraints. \n",
    "\n",
    "Let $x^*$ be the optimal solution of this problem. That is, $f(x^*)$ is the least value for the objective function over \n",
    "the feasible set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Lagrangean of the above problem as :\n",
    "    \\begin{equation}\n",
    "        L(x,\\lambda,\\gamma) = f(x) + \\sum_i^{n} \\lambda_i g_i(x) + \\sum_i^{m} \\gamma_i h_i(x)\n",
    "    \\end{equation}\n",
    "    \n",
    "where $\\lambda_i$s and $\\gamma_i$s are called the Lagrangean multipliers.\n",
    "\n",
    "Let us define $r(\\lambda, \\gamma) $ to be :\n",
    "             \\begin{equation}\n",
    "               r(\\lambda,\\gamma) = \\min_x  L(x,\\lambda,\\gamma)\n",
    "             \\end{equation}\n",
    "For any fixed Lagrangean multipliers $r(\\lambda,\\gamma)$ represents the least value of the Lagrangean function $L$. Therefore $r(\\lambda,\\gamma)$ satisfies the following inequality:\n",
    "For any $\\lambda $ and $\\gamma$ therefore :\n",
    "              \\begin{equation}\n",
    "                  r(\\lambda,\\gamma) \\leq L(x^*,\\lambda,\\gamma) \\leq f(x^*)\n",
    "              \\end{equation}\n",
    "The last inequality comes from the fact that the term $\\sum_i^{n} \\lambda_i g_i(x)$ is non-positive and $\\sum_i^{m} \\gamma_i h_i(x)=0$ since $x^*$ is \n",
    "a feasible point of the original problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This observation leads to the formulation of the dual problem. Since the $r(\\lambda,\\gamma), \\lambda \\geq 0$ is always lower than the optimal objecitve function value $f(x^*)$, we are free to maximize $r$ subject to $\\lambda \\geq 0$. The expection is that the maximum value will be a good lower bound of the primal problem objective function value. In fact under certain conditions they will be equal to each other.\n",
    "\n",
    "Therefore we have a dual problem given by :\n",
    "              \\begin{align}\n",
    "                \\max_{\\lambda,\\gamma} \\; &r(\\lambda,\\gamma)\\\\\n",
    "                subject\\; to \\;& \\lambda \\geq 0\n",
    "               \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\lambda^*,\\gamma^*$ be the optimal solutions of the dual problem. If $r(\\lambda^*,\\gamma^*) < f(x^*)$ then we say the problem is weakly dual. If they are equal then we say they are strongly dual. In the case of strong duality, we need to solve only the dual problem, to get the optimal value of the primal problem. \n",
    "\n",
    "There are some conditions for the existence of strong duality like Slater's conditions. We don't go into them, but in the case of our problem Slater's conditions are satisfied and hence our SVM problem is strongly dual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karush Kuhn Tucker conditions for optimality: (KKT conditions)\n",
    "\n",
    "KKT conditions hold when strong duality is applicable. Because of strong duality we have, $r(\\lambda^*,\\gamma^*) = f(x^*)$. That is, $r(\\lambda^*,\\gamma^*) = \\min_x L(x,\\lambda^*, \\gamma^*) = \\min_x L(x,\\lambda^*, \\gamma^*)$. Therefore we can say that $x^*$ is a minimizer of $L$ at $\\lambda^*, \\gamma^*$. Hence the gradient of $L$ with respect to $x$ at $x^*$ should be $0$. This observation leads to the first KKT condition:\n",
    "1. $\\nabla f(x^*)+\\sum_i^{n} \\lambda_i \\nabla g_i(x^*) + \\sum_i^{m} \\gamma_i \\nabla h_i(x^*) = 0$\n",
    "2. $\\lambda \\geq 0$ (Follows from the dual problem definition) <br>\n",
    "3. $g_i(x^*) \\leq 0 \\forall i = 1 \\cdots n$ (Because $x^*$ is a feasible point of Primal Problem)<br>\n",
    "Now because of strong duality $f(x^*) = L(x^*,\\lambda^*,\\gamma^*) = f(x^*) + \\sum_{i} \\lambda_i g_i(x^*) + \\sum_{i} \\gamma_i h_i(x^*)$. Therefore \n",
    "5. $\\lambda_i g_i(x^*) = 0$\n",
    "4. $h_i(x^*) = 0 \\forall i = 1 \\cdots m$ (Because $x^*$ is a feasible point of Primal Problem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
