{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will use the dataset that we had used for the second assignment for this one also. \n",
    "- The problem is to find a linear separating hyper-plane using logistic regression.\n",
    "- Use tensorflow to implement the gradient descent procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are more than two classes then we have to modify the basic logistic regression procedure to account for the different classes. In this case $Y \\in \\{0,1,2,\\cdots K-1 \\} $ when there are $K$ classes. Here we model the conditional probability of class label to be $k$ as : $P(y=k | x) = \\frac{e^{w_k^Tx}}{1+e^{w_k^Tx}}$. This makes the system more complex than logistic regression as there are $k$ sets of parameters $\\{w_1,w_2,  \\cdots w_K \\}$. We will have to frame \n",
    "the expression for negative log likelihood interms of these parameters:\n",
    "\\begin{equation}\n",
    "  nll = -\\sum_i^n \\delta(y_i,k) log(P(y_i=k | x_i) = -\\sum_i^n \\delta(y_i,k) \\frac{e^{w_k^Tx_i}}{1+e^{w_k^Tx_i}}\n",
    "\\end{equation}\n",
    "where $\\delta(y_i,k) = 1$ if $y_i=k$ and $0$ otherwise. This is called **Softmax Regression**\n",
    "\n",
    "We perform gradient descent on nll with respect to both parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mnist import MNIST\n",
    "\n",
    "'''\n",
    "\n",
    "download mnist data from \"http://yann.lecun.com/exdb/mnist/\" to a directory. Extract them and rename the files as :\n",
    "train-images.idx3-ubyte:  training set images   -----> train-images-idx3-ubyte\n",
    "train-labels.idx1-ubyte:  training set labels   -------> train-labels-idx1-ubyte\n",
    "t10k-images.idx3-ubyte:   test set images    --------> t10k-images-idx3-ubyte\n",
    "t10k-labels.idx1-ubyte: test image labels ----------> t10k-labels-idx1-ubyte\n",
    "\n",
    "Each data sample is a vector of dimensions 784. The vectors are handwritten digit images of size 28x28 vectorized to \n",
    "784 dimensional vector. The labels are 0 to 9. \n",
    "\n",
    "First we will do a logistic regression with two classes or two digits. Select 5 and 1. They have very dissimilar shapes\n",
    "hopefully more easily classifiable than, say 5 and 6. For that use the choose_digits functions which returns two sets of \n",
    "vectors corresponding to the two chosen digits.\n",
    "\n",
    "Using this set data we will do logistic regression and get it tested using the testing data also provided.\n",
    "\n",
    "'''\n",
    "mndata = MNIST('data_directory')\n",
    "img_tr,img_label = mndata.load_training()\n",
    "img_test, img_test_label = mndata.load_testing()\n",
    "\n",
    "img_tr = np.array(img_tr)\n",
    "img_label = np.array(img_label)\n",
    "\n",
    "img_test = np.array(img_test)\n",
    "img_test_label = np.array(img_test_label)\n",
    "\n",
    "def choose_digits(digit_1, digit_2, x_data, y_data):\n",
    "    x_tr_1 = x_data[y_data==digit_1,:]\n",
    "    x_tr_2 = x_data[y_data==digit_2,:]\n",
    "    return x_tr_1, x_tr_2\n",
    "\n",
    "x_tr_1,x_tr_2 = choose_digits(5,1, img_tr,img_label)\n",
    "x_test_1,x_test_2 = choose_digits(5,1,img_test,img_test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assign class label y=0 to digit_1 and y=1 to digit_2\n",
    "- Perform logistic regression classification on the data\n",
    "- Compute the accuracy of classification\n",
    "- The weight vector $w$ is 784 long vector, reshape it to 28xc28 and display it.\n",
    "- Modify the program to make it softmax regression.(Now there will be two parameters $w_1$ and $w_2$)\n",
    "- Display both the parameters and display them as images of size 28x28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modify choose_digits function to retrieve more than two digits and perform softmax regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
